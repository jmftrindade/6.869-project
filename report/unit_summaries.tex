\subsection{Unit Summaries as Dimensions for Clustering}
\label{ss:approach_feature_vectors}

To understand how semantic concepts of similar granularity are learned by each individual layer in a network we propose a clustering-based approach.  Specifically, for each labeled image on the validation data set, we extract a feature vector that summarizes how each unit is individually activated by the input image, as shown in Figure~\ref{fig:vectorization}.  The intuition here is that images which activate similar sets of units from the same layer -- and in similar amounts for each unit -- are likely to contain similar visual concepts.  Therefore, this notion of similarity should be captured by the  feature vector even when the summarization step loses some information, e.g., the shape of activated pixels, or its exact location in the activation image.

Another way to look at this approach is as a collaborative filtering task, commonly used in recommendation systems.  Whereas a recommendation system would suggest who to follow or what books to buy based on similar ratings for the same subset of books, here our collaborative filtering recommends similar images to an input image based on similar amounts of activation on the same units in the layer.  If those units activate for similar concepts in a closely related fashion, then the final cluster is expected to be cohesive and to present visual evidence of that semantic concept.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/vectorization}
\caption{Feature vector obtained for each input image from summarizing its activations on a given CNN layer.}
\label{fig:vectorization}
\end{figure}