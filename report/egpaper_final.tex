\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[usenames,dvipsnames]{color}
\usepackage{color}
\usepackage{etoolbox}
\usepackage{listings}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{verbatim}
\robustify{\cite}


\definecolor{todo-color}{rgb}{1,0,0}
\newcommand{\todo}[1]{\textnormal{\color{todo-color}{\textbf{#1}}}\unskip}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
%\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
\title{Activation Maps Summarization for CNN Interpretability}

\author{Joana M. F. da Trindade\\
MIT CSAIL\\
{\tt\small jfon@mit.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and Matthew Perron\\
MIT CSAIL\\
{\tt\small mperron@mit.edu}
}

\maketitle
%\thispagestyle{empty}

\begin{abstract}
Convolutional Neural Networks (CNNs) are the most effective tools for image classification tasks, yet they remain a black box. Recent work has attempted to improve the ``interpretability'' of CNNs by discovering what each unit in a network learns, one at a time. We propose two method for summarizing whole layers of a CNN, reducing the volume of information to inspect while remaining a powerful method for visually explaining the behavior of these models. We find that our proposed methods allow us to recover perturbations on correctly classified inputs, and find clusters of similar images, visually suggesting the kinds of concepts learned at each layer.
\end{abstract}

\input{introduction}
\input{approach}
\input{experiments}
\input{related_work}
\input{conclusion}
%\input{contributions}

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
