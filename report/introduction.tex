\section{Introduction}

Convolutional Neural Networks (CNNs) are an increasingly important tool for image classification and object detection tasks, in part due to gains in prediction accuracy unattainable by non-neural network based approaches.  The way these models work, however, is still somewhat of a mystery.  For example, it is difficult to understand why certain images are more easily detected or correctly classified than others.  Challenges include: models are opaque (``cognitive black-box''), and intermediate stages in the model are prohibitively large, which makes it hard to choose which parts of a network to focus on when trying to ``debug'' it.

Recent research has focused on solving the problem of increasing deep neural networks ``interpretability''. The approaches vary from visualizing how individual neurons in the network (also referred to as ``units'' or ``channels'') activate for a given stimulus (the input image). The set of activated pixels in a channel when provided with an input image can also be seen as image.  Therefore, by inspecting how these ``activation images'' change in response to changes in the input stimuli, one can try and draw conclusions regarding which individual neurons are responsible for ``learning'' a concept. It makes sense then that some of the proposed techniques in this space include visualizing the top most activated images for a given unit~\cite{netdissect_2017}, or how individual neuron responses change when stimuli is perturbed~\cite{inverting_2014, intraclass_2015}.  The hope is that a quantitative or qualitative assessment of these changes is likely to increase our understanding of what the network is doing.

A drawback of these techniques, however, is that they either rely on a large amount of information from the network (e.g., all individual unit activations, of which there are tens of thousands for a single input image) or selectively ignore large parts of it (e.g., only activations for the deepest layers in the network are considered).

We believe that there is an area of this search space which has not received sufficient attention: a hybrid approach that considers all activations at each layer, while drastically reducing the total amount of information preserved about the network. Specifically, in this project we propose using aggregate statistics and traditional machine learning methods to aggressively summarize CNN intermediates.  We propose two primary granularities of summarization: layer summaries, and unit summaries.  Finally, we qualitatively evaluate how much information these two approaches manage to capture about the network -- even when aggregate statistics used to produce each summary do not retain spatial information originally encoded on activations.
